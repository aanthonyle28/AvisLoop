---
phase: 12-cron-processing
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - supabase/migrations/00010_claim_due_scheduled_sends.sql
  - app/api/cron/process-scheduled-sends/route.ts
  - vercel.json
autonomous: true

must_haves:
  truths:
    - "Cron endpoint fetches due scheduled sends (scheduled_for <= now, status = pending) and sends emails"
    - "System re-validates opt-out, cooldown, quota, and archived status at send time"
    - "Service role client bypasses RLS so cron operates without user session"
    - "Each cron run returns structured JSON with processed/sent/failed/skipped counts"
    - "Concurrent cron invocations cannot double-process the same scheduled send (FOR UPDATE SKIP LOCKED)"
  artifacts:
    - path: "supabase/migrations/00010_claim_due_scheduled_sends.sql"
      provides: "Postgres function for atomic claim of due scheduled sends"
      contains: "claim_due_scheduled_sends"
    - path: "app/api/cron/process-scheduled-sends/route.ts"
      provides: "GET handler for cron processing"
      exports: ["GET"]
    - path: "vercel.json"
      provides: "Vercel cron schedule configuration"
      contains: "crons"
  key_links:
    - from: "app/api/cron/process-scheduled-sends/route.ts"
      to: "supabase/migrations/00010_claim_due_scheduled_sends.sql"
      via: "supabase.rpc('claim_due_scheduled_sends')"
      pattern: "rpc.*claim_due_scheduled_sends"
    - from: "app/api/cron/process-scheduled-sends/route.ts"
      to: "lib/supabase/service-role.ts"
      via: "createServiceRoleClient import"
      pattern: "createServiceRoleClient"
    - from: "app/api/cron/process-scheduled-sends/route.ts"
      to: "lib/email/resend.ts"
      via: "resend.emails.send"
      pattern: "resend\\.emails\\.send"
    - from: "app/api/cron/process-scheduled-sends/route.ts"
      to: "lib/email/templates/review-request.tsx"
      via: "ReviewRequestEmail render"
      pattern: "ReviewRequestEmail"
    - from: "app/api/cron/process-scheduled-sends/route.ts"
      to: "lib/constants/billing.ts"
      via: "COOLDOWN_DAYS, MONTHLY_SEND_LIMITS imports"
      pattern: "COOLDOWN_DAYS|MONTHLY_SEND_LIMITS"
---

<objective>
Create the cron route handler that processes scheduled sends in the background every minute.

Purpose: This is the backend engine for scheduled sending. Without it, scheduled sends sit in the database forever. The cron claims due sends atomically via a Postgres function (race-safe with FOR UPDATE SKIP LOCKED), re-validates all business rules at send time, sends emails via Resend, updates scheduled_send records, and returns structured JSON logs.

Output: Postgres migration for atomic claim function + working cron endpoint at /api/cron/process-scheduled-sends + vercel.json cron config
</objective>

<execution_context>
@C:\Users\aanth\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\aanth\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

Key source files to reference (read these before implementing):
@lib/actions/send.ts (validation logic to replicate: cooldown, opt-out, archived, quota checks)
@lib/supabase/service-role.ts (service role client to import)
@lib/email/resend.ts (resend client + RESEND_FROM_EMAIL)
@lib/email/templates/review-request.tsx (ReviewRequestEmail component)
@lib/types/database.ts (ScheduledSend type)
@lib/constants/billing.ts (COOLDOWN_DAYS, MONTHLY_SEND_LIMITS)
@supabase/migrations/ (existing migration naming convention)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Postgres migration for atomic claim function</name>
  <files>supabase/migrations/00010_claim_due_scheduled_sends.sql</files>
  <action>
Create a new Supabase migration file `supabase/migrations/00010_claim_due_scheduled_sends.sql`.

This migration creates a Postgres function that atomically claims pending scheduled sends using `FOR UPDATE SKIP LOCKED` to prevent race conditions when multiple cron invocations overlap.

```sql
-- Atomically claim pending scheduled sends that are due for processing.
-- Uses FOR UPDATE SKIP LOCKED to prevent race conditions between
-- concurrent cron invocations.
CREATE OR REPLACE FUNCTION claim_due_scheduled_sends(limit_count INT DEFAULT 50)
RETURNS SETOF scheduled_sends AS $$
  UPDATE scheduled_sends
  SET status = 'processing'
  WHERE id IN (
    SELECT id FROM scheduled_sends
    WHERE status = 'pending' AND scheduled_for <= now()
    ORDER BY scheduled_for ASC
    LIMIT limit_count
    FOR UPDATE SKIP LOCKED
  )
  RETURNING *;
$$ LANGUAGE sql;
```

Follow existing migration naming convention (sequential `00010_` prefix). The function:
- Accepts an optional `limit_count` parameter (default 50) to cap batch size
- Selects rows with `status = 'pending'` and `scheduled_for <= now()`
- Orders by `scheduled_for ASC` (oldest first)
- Locks rows with `FOR UPDATE SKIP LOCKED` so concurrent calls skip already-locked rows
- Atomically updates matched rows to `status = 'processing'`
- Returns the full rows via `RETURNING *`
  </action>
  <verify>
Verify the migration file exists and contains valid SQL: read the file back and confirm it contains `CREATE OR REPLACE FUNCTION claim_due_scheduled_sends`, `FOR UPDATE SKIP LOCKED`, and `RETURNING *`.
  </verify>
  <done>
Migration file exists at `supabase/migrations/00010_claim_due_scheduled_sends.sql` with a Postgres function that atomically claims due scheduled sends using FOR UPDATE SKIP LOCKED.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create cron route handler with atomic claim via RPC, validation, and send logic</name>
  <files>app/api/cron/process-scheduled-sends/route.ts</files>
  <action>
Create a Next.js Route Handler (GET) at `app/api/cron/process-scheduled-sends/route.ts`.

**Authentication:**
- Read `CRON_SECRET` from `process.env`
- Compare against `Authorization: Bearer <token>` header
- If missing or mismatch, return 401 JSON `{ error: "Unauthorized" }`
- If `CRON_SECRET` env var is not set, log a warning and return 500

**Claim due sends (atomic, race-safe via RPC):**
- Use `createServiceRoleClient()` from `@/lib/supabase/service-role`
- Call the Postgres function created in Task 1:
  ```typescript
  const { data: claimedSends, error: claimError } = await supabase
    .rpc('claim_due_scheduled_sends', { limit_count: 50 })
  ```
- If `claimError`, return 500 with error details
- If no rows returned (`!claimedSends || claimedSends.length === 0`), return 200 with `{ ok: true, claimed: 0, results: { processed: 0, sent: 0, failed: 0, skipped: 0 } }`
- IMPORTANT: Do NOT use a two-step select-then-update approach. The RPC call handles both atomically.

**Process each claimed scheduled send:**
For each claimed `ScheduledSend`:

1. **Fetch business data** using service role client:
   ```
   .from('businesses').select('id, name, google_review_link, default_sender_name, tier').eq('id', scheduledSend.business_id).single()
   ```
   If business not found or missing google_review_link, mark as 'failed' with error message.

2. **Check monthly quota** (reuse logic from send.ts):
   - Get monthly send count: query `send_logs` where `business_id` matches, `created_at >= start of current month`, status in `['sent', 'delivered', 'opened']`, count exact.
   - Compare against `MONTHLY_SEND_LIMITS[business.tier]`
   - If quota exceeded, mark scheduled_send as 'failed' with quota error.

3. **Fetch all contacts** in one query:
   ```
   .from('contacts').select('id, name, email, status, opted_out, last_sent_at, send_count').in('id', scheduledSend.contact_ids).eq('business_id', scheduledSend.business_id)
   ```

4. **Re-validate each contact** (mirrors batchSendReviewRequest logic):
   - Skip if `status === 'archived'` (reason: 'archived')
   - Skip if `opted_out === true` (reason: 'opted_out')
   - Skip if cooldown active: `last_sent_at` exists and `new Date(last_sent_at) > new Date(Date.now() - COOLDOWN_DAYS * 24 * 60 * 60 * 1000)` (reason: 'cooldown')
   - Skip if contact not found in query results (reason: 'not_found')
   - Collect eligible contacts and skipped contacts with reasons

5. **Fetch template** if `scheduledSend.template_id` is set:
   ```
   .from('email_templates').select('name, subject, body').eq('id', scheduledSend.template_id).eq('business_id', scheduledSend.business_id).single()
   ```

6. **Send emails to eligible contacts** (mirrors batchSendReviewRequest loop):
   - Determine subject: `scheduledSend.custom_subject || template?.subject || "${business.name} would love your feedback!"`
   - Determine senderName: `business.default_sender_name || business.name`
   - For each eligible contact:
     a. Create send_log with status 'pending' via service role client
     b. Render `ReviewRequestEmail` with `{ customerName, businessName, reviewLink, senderName }`
     c. Send via `resend.emails.send()` with from, to, subject, html, tags (send_log_id, business_id), idempotencyKey
     d. Update send_log status to 'sent' or 'failed'
     e. If sent, update contact `last_sent_at` and `send_count`
     f. Track result (sent/failed) and collect send_log_ids

7. **Update scheduled_send record:**
   - If all contacts were processed (even if some skipped/failed):
     - status: any sent > 0 ? 'completed' : 'failed'
     - executed_at: new Date().toISOString()
     - send_log_ids: array of created send log IDs (or null if none)
     - error_message: if all failed, concatenate reasons; if partial, note "X sent, Y skipped, Z failed"

**Return structured JSON response (always 200):**
```json
{
  "ok": true,
  "timestamp": "2026-01-29T...",
  "claimed": 5,
  "results": {
    "processed": 5,
    "sent": 12,
    "failed": 1,
    "skipped": 3
  }
}
```
Return 200 even for partial failures (Vercel Cron expects 200 for success). Only return non-200 for auth failures or catastrophic errors.

**Error handling:**
- Wrap the entire handler in try/catch
- If the outer try/catch fires, return 500 with `{ ok: false, error: message }`
- Each individual scheduled send should be wrapped in its own try/catch so one failure does not block others
- If a scheduled send fails catastrophically, update its status to 'failed' with the error message

**Imports needed:**
- `createServiceRoleClient` from `@/lib/supabase/service-role`
- `resend, RESEND_FROM_EMAIL` from `@/lib/email/resend`
- `ReviewRequestEmail` from `@/lib/email/templates/review-request`
- `render` from `@react-email/render`
- `COOLDOWN_DAYS, MONTHLY_SEND_LIMITS` from `@/lib/constants/billing`
- `NextResponse` from `next/server` (for type, but use `Response` or `NextResponse.json()`)
- Do NOT use `'use server'` directive (this is a Route Handler, not a Server Action)
- Do NOT import `createClient` from `@/lib/supabase/server` (that's the SSR client with user sessions)

**Export:** `export const dynamic = 'force-dynamic'` to prevent caching.
  </action>
  <verify>
Run `pnpm typecheck` to confirm no type errors. Manually verify the file exists and has the correct structure by reading it back. Confirm it uses `supabase.rpc('claim_due_scheduled_sends')` and NOT a two-step select-then-update pattern.
  </verify>
  <done>
Route handler exists at app/api/cron/process-scheduled-sends/route.ts. It exports GET and dynamic. It uses createServiceRoleClient (not createClient). It validates CRON_SECRET. It claims pending scheduled sends via `supabase.rpc('claim_due_scheduled_sends')` (atomic, race-safe). It re-validates each contact (cooldown, opt-out, archived, quota), sends via Resend, updates scheduled_send and send_log records, and returns structured JSON with counts.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create vercel.json with cron schedule configuration</name>
  <files>vercel.json</files>
  <action>
Create `vercel.json` at project root with cron configuration:

```json
{
  "crons": [
    {
      "path": "/api/cron/process-scheduled-sends",
      "schedule": "* * * * *"
    }
  ]
}
```

This runs the cron every minute. Vercel automatically adds the `Authorization: Bearer <CRON_SECRET>` header when invoking cron jobs.

Note: `CRON_SECRET` must be set as an environment variable in Vercel project settings. Vercel auto-generates this if not set, but it must match what the route handler checks.
  </action>
  <verify>
Verify the file is valid JSON: `node -e "JSON.parse(require('fs').readFileSync('vercel.json','utf8'))"` should not throw.
  </verify>
  <done>
vercel.json exists at project root with crons array containing the process-scheduled-sends path with "* * * * *" schedule.
  </done>
</task>

</tasks>

<verification>
1. `pnpm typecheck` passes with no errors
2. `pnpm lint` passes
3. `supabase/migrations/00010_claim_due_scheduled_sends.sql` exists with `FOR UPDATE SKIP LOCKED` atomic claim function
4. `app/api/cron/process-scheduled-sends/route.ts` exports GET function and `dynamic = 'force-dynamic'`
5. Route handler calls `supabase.rpc('claim_due_scheduled_sends')` (NOT a two-step select-then-update)
6. Route handler imports `createServiceRoleClient` (NOT `createClient` from server)
7. Route handler validates CRON_SECRET from Authorization header
8. Route handler re-validates contacts (cooldown, opt-out, archived status, quota)
9. Route handler uses `resend.emails.send()` with ReviewRequestEmail template
10. Route handler updates scheduled_send status to 'completed' or 'failed' with executed_at
11. Route handler returns 200 with structured JSON counts
12. `vercel.json` is valid JSON with crons array
</verification>

<success_criteria>
- Postgres function `claim_due_scheduled_sends()` uses FOR UPDATE SKIP LOCKED for race-safe atomic claiming
- Cron endpoint at /api/cron/process-scheduled-sends handles GET requests
- CRON_SECRET authentication prevents unauthorized access
- Due scheduled sends (pending + scheduled_for <= now) are claimed atomically via RPC
- Each contact is re-validated at send time (not trusting schedule-time validation)
- Emails are sent via existing Resend infrastructure with ReviewRequestEmail template
- scheduled_sends records are updated with final status, executed_at, send_log_ids
- Structured JSON response includes processed/sent/failed/skipped counts
- vercel.json configures every-minute cron schedule
- TypeScript compiles without errors
</success_criteria>

<output>
After completion, create `.planning/phases/12-cron-processing/12-01-SUMMARY.md`
</output>
